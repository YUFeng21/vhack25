import { Base } from "../../resources/base";
import { ModelInfoRequest, ModelInfoResponse, ModelNamesRequest, ModelNamesResponse } from "../../resources/llm/model";
import { ChatCompletionChunk, ChatRequest } from "../../resources/llm/chat";
export declare class LLM extends Base {
    modelInfo(params?: ModelInfoRequest): Promise<ModelInfoResponse>;
    modelNames(params?: ModelNamesRequest): Promise<ModelNamesResponse>;
    generateChatCompletionsStream(params: ChatRequest): Promise<ReadableStream<{
        object: "chat.completion" | "chat.completion.chunk";
        id: string;
        model: string;
        created: number;
        choices: ({
            message: {
                role: "function" | "system" | "user" | "assistant";
                content: string;
                name?: string | null | undefined;
            };
            index: number;
            finish_reason: string | null;
        }[] | {
            message: {
                role: "function" | "system" | "user" | "assistant";
                content: string;
                name?: string | null | undefined;
            };
            index: number;
            finish_reason: string | null;
            delta: {
                role: "function" | "system" | "user" | "assistant";
                content: string;
                name?: string | null | undefined;
            } | null;
        }[]) & ({
            message: {
                role: "function" | "system" | "user" | "assistant";
                content: string;
                name?: string | null | undefined;
            };
            index: number;
            finish_reason: string | null;
        }[] | {
            message: {
                role: "function" | "system" | "user" | "assistant";
                content: string;
                name?: string | null | undefined;
            };
            index: number;
            finish_reason: string | null;
            delta: {
                role: "function" | "system" | "user" | "assistant";
                content: string;
                name?: string | null | undefined;
            } | null;
        }[] | undefined);
        usage?: {
            prompt_tokens?: number | null | undefined;
            completions_tokens?: number | null | undefined;
            total_tokens?: number | null | undefined;
        } | undefined;
        references?: {
            object: string;
        } | null | undefined;
    }>>;
    generateChatCompletions(params: ChatRequest): Promise<ChatCompletionChunk>;
}
